# SafeOS Guardian - Docker Compose Configuration
# Run: docker-compose up -d

version: '3.8'

services:
  # =============================================================================
  # Backend API Server
  # =============================================================================
  api:
    build:
      context: .
      target: backend
    container_name: safeos-api
    restart: unless-stopped
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=production
      - SAFEOS_PORT=3001
      - SAFEOS_DB_PATH=/app/db_data/safeos.sqlite3
      - OLLAMA_HOST=${OLLAMA_HOST:-http://host.docker.internal:11434}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID:-}
      - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN:-}
      - TWILIO_PHONE_NUMBER=${TWILIO_PHONE_NUMBER:-}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN:-}
    volumes:
      - safeos-data:/app/db_data
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - safeos-network
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # =============================================================================
  # Frontend UI
  # =============================================================================
  ui:
    build:
      context: .
      target: frontend
    container_name: safeos-ui
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=http://localhost:3001
      - NEXT_PUBLIC_WS_URL=ws://localhost:3001
    depends_on:
      api:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    networks:
      - safeos-network

  # =============================================================================
  # Redis (Optional - for production scaling)
  # =============================================================================
  redis:
    image: redis:7-alpine
    container_name: safeos-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - safeos-network
    profiles:
      - production

  # =============================================================================
  # Ollama (Local AI - if not running on host)
  # =============================================================================
  ollama:
    image: ollama/ollama:latest
    container_name: safeos-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama-models:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    networks:
      - safeos-network
    profiles:
      - with-ollama

# =============================================================================
# Volumes
# =============================================================================
volumes:
  safeos-data:
    driver: local
  redis-data:
    driver: local
  ollama-models:
    driver: local

# =============================================================================
# Networks
# =============================================================================
networks:
  safeos-network:
    driver: bridge


